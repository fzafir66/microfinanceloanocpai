{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e101b9-06fa-49a1-97e5-18d75b9f1624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Prediction Probability: [0]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Load the training columns (make sure 'training_columns.pkl' exists in the directory)\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Define a sample input for testing\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 25000,\n",
    "    'AMT_CREDIT': 8000,\n",
    "    'AMT_ANNUITY': 2000,\n",
    "    'AMT_GOODS_PRICE': 5000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Load your saved preprocessor\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"models/1/xgb_classifier.onnx\"  # Ensure this file path is correct\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare input data in the required format for ONNX (numpy array)\n",
    "input_name = session.get_inputs()[0].name\n",
    "test_data_array = test_data_processed\n",
    "\n",
    "# Run the model and get the output\n",
    "prediction = session.run(None, {input_name: test_data_array})[0]\n",
    "\n",
    "# Display the prediction result\n",
    "predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Prediction Probability: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7eab10-f10b-4b6e-87d5-c455319152ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Probability of Non-default (class 0): 0.7245\n",
      "Probability of Default (class 1): 0.2755\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define a sample input for testing\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 25000,\n",
    "    'AMT_CREDIT': 8000,\n",
    "    'AMT_ANNUITY': 2000,\n",
    "    'AMT_GOODS_PRICE': 5000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Load the trained pipeline model (make sure 'best_model.joblib' exists in the directory)\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "\n",
    "# Load the training data structure for column alignment\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Create a DataFrame from the input data\n",
    "new_data_df = pd.DataFrame([new_data_default_risk], columns=training_columns)\n",
    "\n",
    "# Define a function to preprocess and predict new input data\n",
    "def preprocess_and_predict(new_data, model, X_train_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the input data and predict the class and probabilities.\n",
    "\n",
    "    Args:\n",
    "    - new_data (dict): Input data for prediction.\n",
    "    - model (Pipeline): Trained pipeline containing preprocessor and classifier.\n",
    "    - X_train_columns (list): Column names used during training.\n",
    "\n",
    "    Returns:\n",
    "    - prediction (int): Predicted class (0 or 1).\n",
    "    - prediction_proba (list): Probabilities for each class.\n",
    "    \"\"\"\n",
    "    # Ensure new_data is a DataFrame and matches the format used during training\n",
    "    new_data_df = pd.DataFrame([new_data], columns=X_train_columns)\n",
    "\n",
    "    # Preprocess the input data (e.g., scaling and encoding using the fitted pipeline)\n",
    "    processed_data = model.named_steps['preprocessor'].transform(new_data_df)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.named_steps['classifier'].predict(processed_data)\n",
    "    prediction_proba = model.named_steps['classifier'].predict_proba(processed_data)\n",
    "\n",
    "    # Output the prediction and probability\n",
    "    predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "    probability_class_0 = prediction_proba[0][0]\n",
    "    probability_class_1 = prediction_proba[0][1]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Probability of Non-default (class 0): {probability_class_0:.4f}\")\n",
    "    print(f\"Probability of Default (class 1): {probability_class_1:.4f}\")\n",
    "\n",
    "    return prediction[0], prediction_proba[0]\n",
    "\n",
    "# Call the function to predict\n",
    "predicted_class, prediction_proba = preprocess_and_predict(new_data_default_risk, best_model, training_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ef8452-557f-4824-b2ee-c2bb4e836459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Probability of Non-default (class 0): 0.7186\n",
      "Probability of Default (class 1): 0.2814\n",
      "Credit Score Category: Very Poor\n"
     ]
    }
   ],
   "source": [
    "def classify_credit_score(probability_class_0):\n",
    "    \"\"\"\n",
    "    Classify the probability of class 0 into credit score categories.\n",
    "\n",
    "    Args:\n",
    "    - probability_class_0 (float): Probability of class 0 (Non-default).\n",
    "\n",
    "    Returns:\n",
    "    - credit_score (str): The credit score category.\n",
    "    \"\"\"\n",
    "    if 0.9889 <= probability_class_0 <= 1.0:\n",
    "        return \"Excellent\"\n",
    "    elif 0.9811 <= probability_class_0 < 0.9889:\n",
    "        return \"Excellent\"\n",
    "    elif 0.9729 <= probability_class_0 < 0.9811:\n",
    "        return \"Good\"\n",
    "    elif 0.9633 <= probability_class_0 < 0.9729:\n",
    "        return \"Good\"\n",
    "    elif 0.9513 <= probability_class_0 < 0.9633:\n",
    "        return \"Good\"\n",
    "    elif 0.9364 <= probability_class_0 < 0.9513:\n",
    "        return \"Fair\"\n",
    "    elif 0.9154 <= probability_class_0 < 0.9364:\n",
    "        return \"Fair\"\n",
    "    elif 0.8818 <= probability_class_0 < 0.9154:\n",
    "        return \"Poor\"\n",
    "    elif 0.8158 <= probability_class_0 < 0.8818:\n",
    "        return \"Very Poor\"\n",
    "    elif 0.1435 <= probability_class_0 < 0.8158:\n",
    "        return \"Very Poor\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Example: Predict and classify the credit score\n",
    "predicted_class, prediction_proba = preprocess_and_predict(new_data_default_risk, best_model, training_columns)\n",
    "\n",
    "# Extract the probability for class 0\n",
    "probability_class_0 = prediction_proba[0]\n",
    "\n",
    "# Classify the credit score\n",
    "credit_score = classify_credit_score(probability_class_0)\n",
    "\n",
    "# Output the credit score classification\n",
    "print(f\"Credit Score Category: {credit_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68504af6-a304-43a1-ac26-b95606554302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Probability of Non-default (class 0): 0.9497\n",
      "Probability of Default (class 1): 0.0503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define a sample input for testing\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 150000,            # Higher income\n",
    "    'AMT_CREDIT': 200000,                  # Lower credit amount\n",
    "    'AMT_ANNUITY': 10000,                  # Lower annuity relative to income\n",
    "    'AMT_GOODS_PRICE': 180000,             # Lower goods price relative to income\n",
    "    'DAYS_BIRTH': -12000,                  # Middle-aged\n",
    "    'DAYS_EMPLOYED': -3000,                # Long-term employment\n",
    "    'REGION_POPULATION_RELATIVE': 0.02,    # Less densely populated area\n",
    "    'CNT_FAM_MEMBERS': 2,                  # Smaller family size\n",
    "    'FLAG_MOBIL': 1,                       # Owns a mobile phone\n",
    "    'FLAG_EMAIL': 1,                       # Has an email\n",
    "    'FLAG_WORK_PHONE': 1,                  # Has a work phone\n",
    "    # Encoded categorical features based on a lower-risk profile\n",
    "    'NAME_INCOME_TYPE_Working': 1,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 0,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 1,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 0,\n",
    "    'NAME_FAMILY_STATUS_Married': 1,\n",
    "    'NAME_FAMILY_STATUS_Single': 0,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 0,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 1,\n",
    "}\n",
    "\n",
    "# Load the trained pipeline model (make sure 'best_model.joblib' exists in the directory)\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "\n",
    "# Load the training data structure for column alignment\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Create a DataFrame from the input data\n",
    "new_data_df = pd.DataFrame([new_data_default_risk], columns=training_columns)\n",
    "\n",
    "# Define a function to preprocess and predict new input data\n",
    "def preprocess_and_predict(new_data, model, X_train_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the input data and predict the class and probabilities.\n",
    "\n",
    "    Args:\n",
    "    - new_data (dict): Input data for prediction.\n",
    "    - model (Pipeline): Trained pipeline containing preprocessor and classifier.\n",
    "    - X_train_columns (list): Column names used during training.\n",
    "\n",
    "    Returns:\n",
    "    - prediction (int): Predicted class (0 or 1).\n",
    "    - prediction_proba (list): Probabilities for each class.\n",
    "    \"\"\"\n",
    "    # Ensure new_data is a DataFrame and matches the format used during training\n",
    "    new_data_df = pd.DataFrame([new_data], columns=X_train_columns)\n",
    "\n",
    "    # Preprocess the input data (e.g., scaling and encoding using the fitted pipeline)\n",
    "    processed_data = model.named_steps['preprocessor'].transform(new_data_df)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.named_steps['classifier'].predict(processed_data)\n",
    "    prediction_proba = model.named_steps['classifier'].predict_proba(processed_data)\n",
    "\n",
    "    # Output the prediction and probability\n",
    "    predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "    probability_class_0 = prediction_proba[0][0]\n",
    "    probability_class_1 = prediction_proba[0][1]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Probability of Non-default (class 0): {probability_class_0:.4f}\")\n",
    "    print(f\"Probability of Default (class 1): {probability_class_1:.4f}\")\n",
    "\n",
    "    return prediction[0], prediction_proba[0]\n",
    "\n",
    "# Call the function to predict\n",
    "predicted_class, prediction_proba = preprocess_and_predict(new_data_default_risk, best_model, training_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b601b3f-7003-45a0-9ea7-226d9c5a92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Probability of Non-default (class 0): 0.9497\n",
      "Probability of Default (class 1): 0.0503\n",
      "Credit Score Category: Fair\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict and classify the credit score\n",
    "predicted_class, prediction_proba = preprocess_and_predict(new_data_default_risk, best_model, training_columns)\n",
    "\n",
    "# Extract the probability for class 0\n",
    "probability_class_0 = prediction_proba[0]\n",
    "\n",
    "# Classify the credit score\n",
    "credit_score = classify_credit_score(probability_class_0)\n",
    "\n",
    "# Output the credit score classification\n",
    "print(f\"Credit Score Category: {credit_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1180d32-37e5-48aa-9d8b-4989fc007a9f",
   "metadata": {},
   "source": [
    "This one is for defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aaa2dee-8bd2-4c9b-a7cf-d1c4d7906042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Default\n",
      "Prediction Probability: [1]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Load the training columns (make sure 'training_columns.pkl' exists in the directory)\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Define a default-risk scenario input for testing\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 10000,  # Extremely low income\n",
    "    'AMT_CREDIT': 200000,  # Extremely high credit amount\n",
    "    'AMT_ANNUITY': 180000,  # Very high annuity amount\n",
    "    'AMT_GOODS_PRICE': 135000,  # Very high goods price\n",
    "    'DAYS_BIRTH': -29200,  # Age: ~82 years\n",
    "    'DAYS_EMPLOYED': 0,  # Unemployed\n",
    "    'REGION_POPULATION_RELATIVE': 0.01,  # Extremely sparsely populated region\n",
    "    'CNT_FAM_MEMBERS': 8,  # Very large family size\n",
    "    'FLAG_MOBIL': 1,  # Has a mobile phone\n",
    "    'FLAG_EMAIL': 0,  # No email\n",
    "    'FLAG_WORK_PHONE': 0,  # No work phone\n",
    "    'NAME_INCOME_TYPE_Working': 1,  # Not Working\n",
    "    'NAME_INCOME_TYPE_Unemployed': 0,  # Unemployed\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,  # No higher education\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,  # Secondary education\n",
    "    'NAME_FAMILY_STATUS_Married': 1,  # Not married\n",
    "    'NAME_FAMILY_STATUS_Single': 0,  # Single\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 0,  # Doesn't own a house/apartment\n",
    "    'NAME_HOUSING_TYPE_With_parents': 1,  # Lives with parents\n",
    "    'OCCUPATION_TYPE_Laborers': 1,  # Laborer\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0  # Not Sales staff\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Load your saved preprocessor\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"models/1/xgb_classifier.onnx\"  # Ensure this file path is correct\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare input data in the required format for ONNX (numpy array)\n",
    "input_name = session.get_inputs()[0].name\n",
    "test_data_array = test_data_processed\n",
    "\n",
    "# Run the model and get the output\n",
    "prediction = session.run(None, {input_name: test_data_array})[0]\n",
    "\n",
    "# Display the prediction result\n",
    "predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Prediction Probability: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c9e060b-48b1-424f-9925-01a3184421da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Default\n",
      "Probability of Non-default (class 0): 0.0597\n",
      "Probability of Default (class 1): 0.9403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define a sample input for testing\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 10000,  # Extremely low income\n",
    "    'AMT_CREDIT': 200000,  # Extremely high credit amount\n",
    "    'AMT_ANNUITY': 180000,  # Very high annuity amount\n",
    "    'AMT_GOODS_PRICE': 135000,  # Very high goods price\n",
    "    'DAYS_BIRTH': -29200,  # Age: ~82 years\n",
    "    'DAYS_EMPLOYED': 0,  # Unemployed\n",
    "    'REGION_POPULATION_RELATIVE': 0.01,  # Extremely sparsely populated region\n",
    "    'CNT_FAM_MEMBERS': 8,  # Very large family size\n",
    "    'FLAG_MOBIL': 1,  # Has a mobile phone\n",
    "    'FLAG_EMAIL': 0,  # No email\n",
    "    'FLAG_WORK_PHONE': 0,  # No work phone\n",
    "    'NAME_INCOME_TYPE_Working': 1,  # Not Working\n",
    "    'NAME_INCOME_TYPE_Unemployed': 0,  # Unemployed\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,  # No higher education\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,  # Secondary education\n",
    "    'NAME_FAMILY_STATUS_Married': 1,  # Not married\n",
    "    'NAME_FAMILY_STATUS_Single': 0,  # Single\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 0,  # Doesn't own a house/apartment\n",
    "    'NAME_HOUSING_TYPE_With_parents': 1,  # Lives with parents\n",
    "    'OCCUPATION_TYPE_Laborers': 1,  # Laborer\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0  # Not Sales staff\n",
    "}\n",
    "\n",
    "# Load the trained pipeline model (make sure 'best_model.joblib' exists in the directory)\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "\n",
    "# Load the training data structure for column alignment\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Create a DataFrame from the input data\n",
    "new_data_df = pd.DataFrame([new_data_default_risk], columns=training_columns)\n",
    "\n",
    "# Define a function to preprocess and predict new input data\n",
    "def preprocess_and_predict(new_data, model, X_train_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the input data and predict the class and probabilities.\n",
    "\n",
    "    Args:\n",
    "    - new_data (dict): Input data for prediction.\n",
    "    - model (Pipeline): Trained pipeline containing preprocessor and classifier.\n",
    "    - X_train_columns (list): Column names used during training.\n",
    "\n",
    "    Returns:\n",
    "    - prediction (int): Predicted class (0 or 1).\n",
    "    - prediction_proba (list): Probabilities for each class.\n",
    "    \"\"\"\n",
    "    # Ensure new_data is a DataFrame and matches the format used during training\n",
    "    new_data_df = pd.DataFrame([new_data], columns=X_train_columns)\n",
    "\n",
    "    # Preprocess the input data (e.g., scaling and encoding using the fitted pipeline)\n",
    "    processed_data = model.named_steps['preprocessor'].transform(new_data_df)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.named_steps['classifier'].predict(processed_data)\n",
    "    prediction_proba = model.named_steps['classifier'].predict_proba(processed_data)\n",
    "\n",
    "    # Output the prediction and probability\n",
    "    predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "    probability_class_0 = prediction_proba[0][0]\n",
    "    probability_class_1 = prediction_proba[0][1]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Probability of Non-default (class 0): {probability_class_0:.4f}\")\n",
    "    print(f\"Probability of Default (class 1): {probability_class_1:.4f}\")\n",
    "\n",
    "    return prediction[0], prediction_proba[0]\n",
    "\n",
    "# Call the function to predict\n",
    "predicted_class, prediction_proba = preprocess_and_predict(new_data_default_risk, best_model, training_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d04a4d9-7455-4d18-92c7-fd289269d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/11/ac/4120dfb74c8e45cce1c664fc7f7ce010edd587ba67ac41489f7432eb9381/onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/fb/b4/31c461eef98b96b8ab736d97274548eaf2b2e349bf09e4de3902f7d53084/flatbuffers-24.12.23-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/app-root/lib64/python3.11/site-packages (from onnxruntime) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from onnxruntime) (24.1)\n",
      "Requirement already satisfied: protobuf in /opt/app-root/lib64/python3.11/site-packages (from onnxruntime) (4.25.5)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib64/python3.11/site-packages (from onnxruntime) (1.13.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m271.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m308.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.12.23 humanfriendly-10.0 onnxruntime-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d358e3-5cad-442a-bcfb-3b9296e8824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/app-root/lib64/python3.11/site-packages (from lime) (3.6.3)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib64/python3.11/site-packages (from lime) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib64/python3.11/site-packages (from lime) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (from lime) (4.67.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/app-root/lib64/python3.11/site-packages (from lime) (1.2.2)\n",
      "Collecting scikit-image>=0.12 (from lime)\n",
      "  Obtaining dependency information for scikit-image>=0.12 from https://files.pythonhosted.org/packages/35/e8/67e4bd1c5f6c4cd0f53505ebb9eb15f143d6fed1fb4938b542013fa3ec25/scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in /opt/app-root/lib64/python3.11/site-packages (from scikit-image>=0.12->lime) (11.0.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image>=0.12->lime)\n",
      "  Obtaining dependency information for imageio!=2.35.0,>=2.33 from https://files.pythonhosted.org/packages/5c/f9/f78e7f5ac8077c481bf6b43b8bc736605363034b3d5eb3ce8eb79f53f5f1/imageio-2.36.1-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.12->lime)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/d8/1e/76cbc758f6865a9da18001ac70d1a4154603b71e233f704401fc7d62493e/tifffile-2024.12.12-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2024.12.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/app-root/lib64/python3.11/site-packages (from scikit-image>=0.12->lime) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.12->lime)\n",
      "  Obtaining dependency information for lazy-loader>=0.4 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Downloading scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m191.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m309.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.12.12-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m342.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283833 sha256=b51b97af3c0ef709d22e50fca5d7d0ae695adf70e7ad2f4fa8f753e35f810b17\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-st0j2ts8/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
      "Successfully built lime\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image, lime\n",
      "Successfully installed imageio-2.36.1 lazy-loader-0.4 lime-0.2.0.1 scikit-image-0.25.0 tifffile-2024.12.12\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed5035-8dc7-4559-88dc-c10a06042c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aeb41-0b96-4511-8eaf-95e6055d8af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
