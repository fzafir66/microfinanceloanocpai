{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f0bd63-7cdd-4fb2-838f-e0cee40d6954",
   "metadata": {},
   "source": [
    "## Test against onnx model that is saved locally\n",
    "\n",
    "If Success, repeat format against model hosted through API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9402b07f-205d-4615-ae03-aec4ccd7be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Prediction Probability: [0]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the training columns (make sure 'training_columns.pkl' exists in the directory)\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "\n",
    "# Define a sample input for testings\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 600000,\n",
    "    'AMT_ANNUITY': 25000,\n",
    "    'AMT_GOODS_PRICE': 550000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Load your saved preprocessor\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"models/1/xgb_classifier.onnx\"  # Ensure this file path is correct\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare input data in the required format for ONNX (numpy array)\n",
    "input_name = session.get_inputs()[0].name\n",
    "test_data_array = test_data_processed\n",
    "\n",
    "# Run the model and get the output\n",
    "prediction = session.run(None, {input_name: test_data_array})[0]\n",
    "\n",
    "# Display the prediction result\n",
    "predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Prediction Probability: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce268f-4fb2-449a-85b9-b46bec9a972c",
   "metadata": {},
   "source": [
    "## Test against model hosted through API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4616d5f2-7fec-4d1d-a666-64fbb1e349ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Prediction Probability: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "\n",
    "infer_url = \"http://modelmesh-serving.demo.svc.cluster.local:8008/v2/models/xgb/infer\"\n",
    "\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Define the sample input\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 600000,\n",
    "    'AMT_ANNUITY': 25000,\n",
    "    'AMT_GOODS_PRICE': 550000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    'EXT_SOURCE_1': 0.1,\n",
    "    'EXT_SOURCE_2': 0.15,\n",
    "    'EXT_SOURCE_3': 0.2,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Flatten the processed data and ensure it’s in a list format\n",
    "data_list = test_data_processed.flatten().tolist()\n",
    "\n",
    "# Define payload with explicit shape, datatype, and the processed data\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"float_input\",  # Use the expected input name if different\n",
    "            \"shape\": [1, len(data_list)],  # Adjust shape to match your data\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": data_list\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define API endpoint and headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(infer_url, headers=headers, data=json.dumps(payload), verify=False)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Extract predictions\n",
    "        prediction = response.json().get(\"outputs\", [{}])[0].get(\"data\")\n",
    "        predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "        print(f\"Predicted Class: {predicted_class}\")\n",
    "        print(f\"Prediction Probability: {prediction}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        print(\"Response content:\", response.json())\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7143ae-f777-40be-9cf4-24dbbc1cd752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Prediction Probability: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "\n",
    "infer_url = \"http://modelmesh-serving.demo.svc.cluster.local:8008/v2/models/xgb/infer\"\n",
    "\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Define the sample input\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 600000,\n",
    "    'AMT_ANNUITY': 25000,\n",
    "    'AMT_GOODS_PRICE': 550000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    # 'EXT_SOURCE_1': 0.1,\n",
    "    # 'EXT_SOURCE_2': 0.15,\n",
    "    # 'EXT_SOURCE_3': 0.2,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Flatten the processed data and ensure it’s in a list format\n",
    "data_list = test_data_processed.flatten().tolist()\n",
    "\n",
    "# Define payload with explicit shape, datatype, and the processed data\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"float_input\",  # Use the expected input name if different\n",
    "            \"shape\": [1, len(data_list)],  # Adjust shape to match your data\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": data_list\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define API endpoint and headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(infer_url, headers=headers, data=json.dumps(payload), verify=False)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Extract predictions\n",
    "        prediction = response.json().get(\"outputs\", [{}])[0].get(\"data\")\n",
    "        predicted_class = \"Default\" if prediction[0] == 1 else \"Non-default\"\n",
    "        print(f\"Predicted Class: {predicted_class}\")\n",
    "        print(f\"Prediction Probability: {prediction}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        print(\"Response content:\", response.json())\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce571d7d-1151-4f92-8eba-1caf1931bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Non-default\n",
      "Prediction Probabilities: [0.8436363, 0.15636373]\n",
      "Error parsing response: LIME model prediction failed.\n",
      "Response content: {'model_name': 'xgb__isvc-858e157a7b', 'model_version': '1', 'outputs': [{'name': 'label', 'datatype': 'INT64', 'shape': [1, 1], 'data': [0]}, {'name': 'probabilities', 'datatype': 'FP32', 'shape': [1, 2], 'data': [0.8436363, 0.15636373]}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Define inference endpoint\n",
    "infer_url = \"http://modelmesh-serving.demo.svc.cluster.local:8008/v2/models/xgb/infer\"\n",
    "\n",
    "# Load necessary files\n",
    "training_columns = joblib.load(\"training_columns.pkl\")\n",
    "best_model = joblib.load(\"best_model.joblib\")\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Load training data for initializing LIME\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "\n",
    "# Initialize LIME explainer\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_train_processed,\n",
    "    feature_names=training_columns,\n",
    "    class_names=[\"Non-default\", \"Default\"],\n",
    "    mode=\"classification\"\n",
    ")\n",
    "\n",
    "# Define the sample input\n",
    "new_data_default_risk = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 600000,\n",
    "    'AMT_ANNUITY': 25000,\n",
    "    'AMT_GOODS_PRICE': 550000,\n",
    "    'DAYS_BIRTH': -16000,\n",
    "    'DAYS_EMPLOYED': 0,\n",
    "    'REGION_POPULATION_RELATIVE': 0.04,\n",
    "    'CNT_FAM_MEMBERS': 4,\n",
    "    'FLAG_MOBIL': 1,\n",
    "    'FLAG_EMAIL': 1,\n",
    "    'FLAG_WORK_PHONE': 0,\n",
    "    'NAME_INCOME_TYPE_Working': 0,\n",
    "    'NAME_INCOME_TYPE_Unemployed': 1,\n",
    "    'NAME_EDUCATION_TYPE_Higher_education': 0,\n",
    "    'NAME_EDUCATION_TYPE_Secondary_education': 1,\n",
    "    'NAME_FAMILY_STATUS_Married': 0,\n",
    "    'NAME_FAMILY_STATUS_Single': 1,\n",
    "    'NAME_HOUSING_TYPE_House_apartment': 1,\n",
    "    'NAME_HOUSING_TYPE_With_parents': 0,\n",
    "    'OCCUPATION_TYPE_Laborers': 1,\n",
    "    'OCCUPATION_TYPE_Sales_staff': 0\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame and reindex to match the training columns\n",
    "test_data = pd.DataFrame([new_data_default_risk])\n",
    "test_data = test_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Preprocess the test data\n",
    "test_data_processed = preprocessor.transform(test_data).astype(np.float32)\n",
    "\n",
    "# Flatten the processed data and ensure it’s in a list format\n",
    "data_list = test_data_processed.flatten().tolist()\n",
    "\n",
    "# Define payload with explicit shape, datatype, and the processed data\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"float_input\",  # Use the expected input name if different\n",
    "            \"shape\": [1, len(data_list)],  # Adjust shape to match your data\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": data_list\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define API endpoint and headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(infer_url, headers=headers, data=json.dumps(payload), verify=False)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Extract predictions\n",
    "        response_json = response.json()\n",
    "        probabilities = None\n",
    "        for output in response_json.get(\"outputs\", []):\n",
    "            if output[\"name\"] == \"probabilities\":\n",
    "                probabilities = output[\"data\"]\n",
    "                break\n",
    "\n",
    "        if probabilities:\n",
    "            predicted_class = \"Default\" if probabilities[1] > 0.5 else \"Non-default\"\n",
    "            print(f\"Predicted Class: {predicted_class}\")\n",
    "            print(f\"Prediction Probabilities: {probabilities}\")\n",
    "        else:\n",
    "            raise ValueError(\"Probabilities not found in response.\")\n",
    "\n",
    "        # Generate LIME explanation\n",
    "        def lime_predict_fn(data):\n",
    "            # Prepare payload for LIME\n",
    "            payload = {\n",
    "                \"inputs\": [\n",
    "                    {\n",
    "                        \"name\": \"float_input\",\n",
    "                        \"shape\": [len(data), len(data[0])],\n",
    "                        \"datatype\": \"FP32\",\n",
    "                        \"data\": data.flatten().tolist()\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            response = requests.post(infer_url, headers=headers, data=json.dumps(payload), verify=False)\n",
    "            if response.status_code == 200:\n",
    "                response_json = response.json()\n",
    "                probabilities = None\n",
    "                for output in response_json.get(\"outputs\", []):\n",
    "                    if output[\"name\"] == \"probabilities\":\n",
    "                        probabilities = output[\"data\"]\n",
    "                        break\n",
    "                if probabilities:\n",
    "                    return np.tile(probabilities, (data.shape[0], 1))\n",
    "                else:\n",
    "                    raise ValueError(\"Probabilities not found in response.\")\n",
    "            else:\n",
    "                raise Exception(\"LIME model prediction failed.\")\n",
    "\n",
    "        # Explain the instance using LIME\n",
    "        explanation = explainer.explain_instance(\n",
    "            data_row=test_data_processed[0],\n",
    "            predict_fn=lime_predict_fn,\n",
    "            num_features=3  # Specify number of top features to extract\n",
    "        )\n",
    "\n",
    "        # Extract top 3 features\n",
    "        top_features = explanation.as_list()\n",
    "        print(\"\\nTop 3 Features and Contributions:\")\n",
    "        for feature, contribution in top_features:\n",
    "            print(f\"{feature}: {contribution}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        print(\"Response content:\", response.json())\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d95a34-ec6c-4edc-bc6f-53b0bdc8ddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
